{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8_MGcV4SZjRN",
        "5pbJPQqdcUOV",
        "YOuvZvq4Zf-V",
        "7vvSWu4_Z85k",
        "4PHdZ64QdYtX",
        "VJ6LuAySdfmG",
        "YuAq1lvGdvta",
        "9zuSR9a3efLn"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7um5xhJQIUC6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import Series\n",
        "from pandas import concat\n",
        "from pandas import read_csv\n",
        "from pandas import datetime\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from tensorflow import keras\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy\n",
        "import os\n",
        "import platform\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import *\n",
        "from numpy import array\n",
        "from keras.layers import Dropout\n",
        "import pywt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vieno įvesties kintamojo metodai"
      ],
      "metadata": {
        "id": "8_MGcV4SZjRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vieno žingsnio prognozės metodai"
      ],
      "metadata": {
        "id": "5pbJPQqdcUOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def atsisiusti_elspot_kainu_duomenis(aplankas, metai):\n",
        "  if not os.path.exists(aplankas):\n",
        "      os.mkdir(aplankas)\n",
        "\n",
        "  for m in metai:\n",
        "    !wget -P {aplankas} https://www.nordpoolgroup.com/49c730/globalassets/marketdata-excel-files-for-media/elspot-prices_{m}_hourly_eur.xls\n",
        "\n",
        "def gauti_duomenu_rinkini(aplankas, kainos_zona):\n",
        "  visi_failai = sorted(glob.glob(os.path.join(aplankas, \"*.xlsx\")))\n",
        "  li = []\n",
        "  for failo_pav in visi_failai:\n",
        "    print(failo_pav)\n",
        "    df = pd.read_excel(failo_pav, header = 1, skiprows=[0])\n",
        "    df = df.rename(columns={'Unnamed: 0': 'Data', 'Hours': 'Valandos'})\n",
        "    if f'{kainos_zona}.1' in df:\n",
        "      df[kainos_zona] = df[kainos_zona].fillna(df[f'{kainos_zona}.1'])\n",
        "    df = df[['Data', 'Valandos', kainos_zona]]\n",
        "    li.append(df)\n",
        "  duomenys = pd.concat(li, axis=0, ignore_index=True)\n",
        "  return duomenys\n",
        "\n",
        "# pašalinti duomenų sezoniškumą\n",
        "def skirtumas(duomenys, intervalas=1):\n",
        "  diff = list()\n",
        "  for i in range(intervalas, len(duomenys)):\n",
        "    verte = duomenys.iloc[i] - duomenys.iloc[i - intervalas]\n",
        "    diff.append(verte)\n",
        "  return Series(diff)\n",
        "\n",
        "# sugrąžinti duomenis iš sezoniškumo pašalintų į pradinius\n",
        "def invertuoti_skirtuma(istorija, yhat, intervalas=1):\n",
        "  return yhat + istorija.iloc[-intervalas]\n",
        "\n",
        "def laiko_eilute_i_priziurejima(duomenys, lag=1):\n",
        "  df = DataFrame(duomenys)\n",
        "  stulpeliai = [df.shift(i) for i in range(1, lag+1)]\n",
        "  stulpeliai.append(df)\n",
        "  df = concat(stulpeliai, axis=1)\n",
        "  df.fillna(0, inplace=True)\n",
        "  return df\n",
        "\n",
        "# padalina duomenis į iš pavyzdžių, laiko žingsnių ir požymių dimensijų susidedančią matricą\n",
        "def dalinti_duomenis(duomenys):\n",
        "  X, y = duomenys[:, 0:-1], duomenys[:, -1]\n",
        "  X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "  return X, y\n",
        "\n",
        "def duomenis_i_skale(train, test):\n",
        "\n",
        "  scaleris = MinMaxScaler(feature_range=(-1, 1))\n",
        "  scaleris = scaleris.fit(train)\n",
        "\n",
        "  train = train.reshape(train.shape[0], train.shape[1])\n",
        "  train_skaleje = scaleris.transform(train)\n",
        "\n",
        "  test = test.reshape(test.shape[0], test.shape[1])\n",
        "  test_skaleje = scaleris.transform(test)\n",
        "\n",
        "  return scaleris, train_skaleje, test_skaleje\n",
        "\n",
        "def duomenis_is_skales(scaleris, X, verte):\n",
        "  nauja_eilute = [x for x in X] + [verte]\n",
        "  array = numpy.array(nauja_eilute)\n",
        "  array = array.reshape(1, len(array))\n",
        "  invertuota = scaleris.inverse_transform(array)\n",
        "  return invertuota[0, -1]\n",
        "\n",
        "def mokyti_ITAMNT(train, rinkinio_dydis, epizodu_sk, neuronu_sk):\n",
        "  device_name = tf.test.gpu_device_name()\n",
        "  if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU nerastas')\n",
        "  print('GPU naudojamas iš: {}'.format(device_name))\n",
        "  X, y = dalinti_duomenis(train)\n",
        "  # X_val, y_val = dalinti_duomenis(val) # kol kas be val bandau\n",
        "  print(f'pavyzdžiai: {rinkinio_dydis}, laiko_žingsniai: {X.shape[1]}, požymiai: {X.shape[2]}')\n",
        "  modelis = Sequential()\n",
        "  modelis.add(LSTM(neuronu_sk, batch_input_shape = (rinkinio_dydis, X.shape[1], X.shape[2]), stateful=True))\n",
        "  modelis.add(Dense(1))\n",
        "  modelis.compile(loss='mean_squared_error', optimizer='adam')\n",
        "  for i in range(epizodu_sk):\n",
        "    print(\"epocha=\" + str(i))\n",
        "    modelis.fit(X, y, epochs=1, batch_size=rinkinio_dydis, verbose=1, shuffle=False)\n",
        "    modelis.reset_states()\n",
        "  return modelis\n",
        "\n",
        "def prognoze(modelis, rinkinio_sk, eile):\n",
        "  X = eile[0: -1]\n",
        "  X = X.reshape(1, 1, len(X))\n",
        "  yhat = modelis.predict(X, batch_size=rinkinio_sk)\n",
        "  return yhat[0,0]\n",
        "\n",
        "def itamnt_prognoze(modelis, rinkinio_dydis, X):\n",
        "  X = X.reshape(1,1, len(X))\n",
        "  yhat = modelis.predict(X, batch_size=rinkinio_dydis)\n",
        "  return yhat[0,0]\n",
        "\n",
        "def prognozuoti(modelis, test_skaleje, raw_duomenys, scaleris):\n",
        "  prognozes = list()\n",
        "  for i in range(len(test_skaleje)):\n",
        "    print(f'{str(i+1)} iš {str(len(test_skaleje))}')\n",
        "    X, y = test_skaleje[i, 0: -1], test_skaleje[i, -1]\n",
        "    yhat = itamnt_prognoze(modelis, 1, X)\n",
        "    yhat = duomenis_is_skales(scaleris, X, yhat)\n",
        "    yhat = invertuoti_skirtuma(raw_duomenys, yhat, len(test_skaleje)+1-i)\n",
        "    prognozes.append(yhat)\n",
        "  return prognozes\n",
        "\n",
        "def paruosti_duomenis_duotame_tarpe(duomenys, kainos_zona, data_nuo, test_sk_procentais):\n",
        "  duom = duomenys[duomenys['Data'].eq(data_nuo).cummax()]\n",
        "  print(\"Imami duomenys nuo...\")\n",
        "  print(duom.head())\n",
        "  duom = duom[kainos_zona].dropna()\n",
        "\n",
        "  duomenys_be_sezonaliskumo = skirtumas(duom)\n",
        "  duom_priziurejimui = laiko_eilute_i_priziurejima(duomenys_be_sezonaliskumo)\n",
        "  priz_vertes = duom_priziurejimui.values\n",
        "  test_dydis = round(test_sk_procentais * priz_vertes.shape[0])\n",
        "  print(f\"Duomenų skaičius validavimui: {str(test_dydis)} Tai yra {str(test_dydis/24)} dienos\")\n",
        "  train_dydis = priz_vertes.shape[0]-test_dydis\n",
        "  print(f\"Duomenų skaičius treniravimui: {str(train_dydis)} Tai yra {str(train_dydis/24)} dienos\")\n",
        "  train, test = priz_vertes[0:train_dydis,:], priz_vertes[train_dydis:,:]\n",
        "  scaleris, train_skaleje, test_skaleje = duomenis_i_skale(train, test)\n",
        "  \n",
        "  return duom, train_skaleje, test_skaleje, scaleris\n",
        "\n",
        "def diagrama(dienos, pavadinimas, kainos_zona, realios_kainos, prognozes):\n",
        "  \n",
        "  rodoma_dalis = 24*dienos\n",
        "  print(f'Vaizduojama nuo: {realios_kainos[-rodoma_dalis:]}')\n",
        "  plt.figure(figsize=(15,7))\n",
        "  plt.title(pavadinimas)\n",
        "  plt.xlabel('Valanda')\n",
        "  plt.ylabel(f'Elektros kaina [EUR] {kainos_zona} zonoje')\n",
        "  plt.plot(range(rodoma_dalis),realios_kainos[-rodoma_dalis:],color='b')\n",
        "  plt.plot(range(rodoma_dalis),prognozes[-rodoma_dalis:], color='r')\n",
        "  plt.legend(['reali kaina', 'prognoze'])\n",
        "  plt.show()\n",
        "\n",
        "def prognozes_tikslumas(test_skaleje, realios_kainos, prognozes):\n",
        "  test_zymos = test_skaleje.shape[0]\n",
        "  rmse = sqrt(mean_squared_error(realios_kainos[-test_zymos:], prognozes))\n",
        "  mae = mean_absolute_error(realios_kainos[-test_zymos:], prognozes)\n",
        "  print(f'VKNŠ = {rmse}')\n",
        "  print(f'VAP = {mae}')\n",
        "\n"
      ],
      "metadata": {
        "id": "t8-uueouceOD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kelių žingsnių prognozės metodai"
      ],
      "metadata": {
        "id": "YOuvZvq4Zf-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gauti_duomenu_rinkini(aplankas, kainos_zona):\n",
        "  visi_failai = sorted(glob.glob(os.path.join(aplankas, \"*.xlsx\")))\n",
        "  li = []\n",
        "  for failo_pav in visi_failai:\n",
        "    print(failo_pav)\n",
        "    df = pd.read_excel(failo_pav, header = 1, skiprows=[0])\n",
        "    df = df.rename(columns={'Unnamed: 0': 'Data', 'Hours': 'Valandos'})\n",
        "    if f'{kainos_zona}.1' in df:\n",
        "      df[kainos_zona] = df[kainos_zona].fillna(df[f'{kainos_zona}.1'])\n",
        "    df = df[['Data', 'Valandos', kainos_zona]]\n",
        "    li.append(df)\n",
        "  duomenys = pd.concat(li, axis=0, ignore_index=True)\n",
        "  return duomenys\n",
        "\n",
        "# pašalinti duomenų sezoniškumą\n",
        "def skirtumas(duomenys, intervalas=1):\n",
        "  diff = list()\n",
        "  for i in range(intervalas, len(duomenys)):\n",
        "    verte = duomenys.iloc[i] - duomenys.iloc[i - intervalas]\n",
        "    diff.append(verte)\n",
        "  return Series(diff)\n",
        "\n",
        "def invertuoti_ms_skirtuma(paskutine_reiksme, prognoze):\n",
        "  invertuoti = list()\n",
        "  print(f'Prognozuojama nuo šios paskutinės reikšmės: {paskutine_reiksme}')\n",
        "  invertuoti.append(prognoze[0] + paskutine_reiksme)\n",
        "  for i in range(1, len(prognoze)):\n",
        "    invertuoti.append(prognoze[i] + invertuoti[i-1])\n",
        "  return invertuoti\n",
        "\n",
        "def invertuoti_transformacijas(duomenys, prognozes, scaleris, test_dydis, koeficientai=\"\"):\n",
        "  invertuoti = list()\n",
        "  for i in range(len(prognozes)):\n",
        "    prognoze = array(prognozes[i])\n",
        "    prognoze = prognoze.reshape(1, len(prognoze))\n",
        "\n",
        "    invertuota_skale = scaleris.inverse_transform(prognoze)\n",
        "    invertuota_skale = invertuota_skale[0, :]\n",
        "\n",
        "    index = len(duomenys) - test_dydis + i #- 1\n",
        "    paskutine_reiksme = duomenys.values[index]\n",
        "    invertuotos = invertuoti_ms_skirtuma(paskutine_reiksme, invertuota_skale)\n",
        "    invertuoti.append(invertuotos)\n",
        "  return invertuoti\n",
        "\n",
        "def laiko_eilute_i_priziurejima_patobulinta(data, n_ivestis=1, n_isvestis=1, dropnan=True):\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = DataFrame(data)\n",
        "\tstulp, pav = list(), list()\n",
        "\t# įvesties seka (t-n, ... t-1)\n",
        "\tfor i in range(n_ivestis, 0, -1):\n",
        "\t\tstulp.append(df.shift(i))\n",
        "\t\tpav += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# išvesties seka (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_isvestis):\n",
        "\t\tstulp.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tpav += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tpav += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\tagg = concat(stulp, axis=1)\n",
        "\tagg.columns = pav\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg\n",
        "\n",
        "\n",
        "def paruosti_duomenis_duotame_tarpe_ms(duomenys, kainos_zona, data_nuo, data_iki, n_ivestis, n_isvestis, test_dydis):#, test_sk_procentais):\n",
        "\n",
        "  duom_pjuvis = duomenys[(duomenys['Data'].eq(data_nuo).cummax()) & (duomenys['Data'] <= data_iki)]\n",
        "  print(f'Imami duomenys nuo:\\n{duom_pjuvis.head()}\\n iki:\\n{duom_pjuvis.tail()}')\n",
        "  # print(f'Prognozojuoma {test_dydis} valandas į priekį bus nuo kiekvieno iš šių taškų:\\n {duom_pjuvis[-test_dydis:]}')\n",
        "  duom = duom_pjuvis[kainos_zona].dropna()\n",
        "\n",
        "  print(\"Naudojama skirtumo f-ja duomenims paruošti\")\n",
        "  duomenys_be_sezonaliskumo = skirtumas(duom)\n",
        "  duomenys_be_sezonaliskumo_vertes = duomenys_be_sezonaliskumo.values\n",
        "  dbsv = duomenys_be_sezonaliskumo_vertes.reshape(len(duomenys_be_sezonaliskumo_vertes), 1)\n",
        "  koeficientai = []\n",
        "\n",
        "  scaleris = MinMaxScaler(feature_range=(-1, 1))\n",
        "  vertes_skaleje = scaleris.fit_transform(dbsv)\n",
        "  vertes_skaleje = vertes_skaleje.reshape(len(vertes_skaleje), 1)\n",
        "\n",
        "  duom_priziurejimui = laiko_eilute_i_priziurejima_patobulinta(vertes_skaleje, n_ivestis, n_isvestis)\n",
        "  priz_vertes = duom_priziurejimui.values\n",
        "  print(f\"t+{n_isvestis} prognozei skirti laiko taškai: {str(test_dydis)}\")\n",
        "  print(f\"Pirmasis prognozės taškas:\\n {duom_pjuvis.iloc[-test_dydis:]}\")\n",
        "  train_dydis = priz_vertes.shape[0]-test_dydis\n",
        "  print(f\"Duomenų skaičius treniravimui: {str(train_dydis)} Tai yra {str(train_dydis/24)} dienos\")\n",
        "  train, test = priz_vertes[0:train_dydis,:], priz_vertes[train_dydis:,:]\n",
        "\n",
        "  realios_test_reiksmes = duom_pjuvis.iloc[-test_dydis:]\n",
        "  prognozuojamu_tasku_pradzia = (realios_test_reiksmes.index)[0]\n",
        "  prognozuojamu_reiksmiu_realios_reiksmes = duomenys.iloc[prognozuojamu_tasku_pradzia:prognozuojamu_tasku_pradzia+n_isvestis*2]\n",
        "\n",
        "  return duom, train, test, scaleris, prognozuojamu_reiksmiu_realios_reiksmes, koeficientai\n",
        "\n",
        "\n",
        "def mokyti_ms_itamnt(train, n_ivestis, n_isvestis, rinkinio_dydis, epizodu_sk, neuronu_sk, checkpoint_kelias=\"\"):\n",
        "\n",
        "  saugoti_kas = 30\n",
        "  saugojimas = 0\n",
        "  X, y = train[:, 0: n_ivestis], train[:, n_ivestis:]\n",
        "  X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\n",
        "  modelis = Sequential()\n",
        "  modelis.add(LSTM(neuronu_sk, batch_input_shape=(rinkinio_dydis, X.shape[1], X.shape[2]), stateful=True, return_sequences=True))\n",
        "  modelis.add(Dropout(0.2))\n",
        "  modelis.add(LSTM(neuronu_sk, stateful=True))\n",
        "  modelis.add(Dropout(0.2))\n",
        "  modelis.add(Dense(y.shape[1]))\n",
        "  modelis.compile(loss='mean_squared_error', optimizer='adam')\n",
        "  # if(checkpoint_kelias != \"\"):\n",
        "  #   print(f'Imamas modelis iš {checkpoint_kelias}')\n",
        "  #   modelis = keras.models.load_model(checkpoint_kelias)\n",
        "\n",
        "  for i in range(epizodu_sk):\n",
        "    print(f'epizodas: {i+1}/{epizodu_sk}')\n",
        "\n",
        "    if ((i+1) % saugoti_kas) == 0:\n",
        "      modelis.save(f'{checkpoint_kelias}/epocha{i+1}')\n",
        "\n",
        "    modelis.fit(X, y, epochs=1, batch_size=rinkinio_dydis, shuffle=False)\n",
        "    modelis.reset_states()\n",
        "  return modelis\n",
        "\n",
        "def ms_itamnt_prognoze(modelis, X, rinkinio_dydis):\n",
        "  X = X.reshape(1,1,len(X))\n",
        "  prognoze = modelis.predict(X, batch_size=rinkinio_dydis)\n",
        "  return [p for p in prognoze[0, :]]\n",
        "\n",
        "def ms_prognoze(modelis, rinkinio_dydis, test, n_ivestis, n_isvestis):\n",
        "  prognozes = list()\n",
        "  for i in range(len(test)):\n",
        "    X, y = test[i, 0:n_ivestis], test[i, n_ivestis:]\n",
        "    prognoze = ms_itamnt_prognoze(modelis, X, rinkinio_dydis)\n",
        "    prognozes.append(prognoze)\n",
        "  return prognozes\n",
        "\n",
        "def ms_diagrama(realios_kainos, prognozes, kainos_zona, pavadinimas=\"\", top_indexai=None, top3=False):\n",
        "\n",
        "  realios_vertes = realios_kainos[kainos_zona].values\n",
        "  print(realios_vertes)\n",
        "  x = np.arange(len(realios_vertes))\n",
        "  prognozes_arr = np.array(prognozes)\n",
        "\n",
        "  plt.figure(figsize=(15,7))\n",
        "  plt.plot(x, realios_vertes, label='Realios kainos', marker='o', linestyle='-')\n",
        "\n",
        "  for i in range(len(prognozes)):#(prognozes_arr.shape[1]):\n",
        "    \n",
        "    if top3:\n",
        "      if i in top_indexai:\n",
        "            x_pred = np.arange(i+1, i + 1 +  prognozes_arr.shape[1])\n",
        "            plt.plot(x_pred, prognozes_arr[i], label=f'Prognozė {i+1}', marker='o', linestyle='--')\n",
        "      else:\n",
        "        continue\n",
        "    else:\n",
        "      x_pred = np.arange(i+1, i + 1 +  prognozes_arr.shape[1])\n",
        "      plt.plot(x_pred, prognozes_arr[i], label=f'Prognozė {i+1}', marker='o', linestyle='--')\n",
        "\n",
        "  plt.legend()\n",
        "  plt.xlabel('Valandos')\n",
        "  plt.ylabel('Kaina')\n",
        "  plt.title(pavadinimas)\n",
        "  plt.show()\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
        "\n",
        "def prognozes_tikslumo_metrikos(realios, prognozes, kainos_zona):\n",
        "  \n",
        "  realios_vertes = realios[kainos_zona].values\n",
        "  prognozes_arr = np.array(prognozes)\n",
        "  n_isvestis = prognozes_arr.shape[1]\n",
        "  errors = []\n",
        "\n",
        "  for i in range(len(prognozes_arr)):\n",
        "      # print(prognozes_arr[i])\n",
        "      # print(realios_vertes[i+1:i+n_isvestis+1])\n",
        "      rmse = root_mean_squared_error(realios_vertes[i+1:i+n_isvestis+1], prognozes_arr[i])\n",
        "      mape = mean_absolute_percentage_error(realios_vertes[i+1:i+n_isvestis+1], prognozes_arr[i])\n",
        "\n",
        "      errors.append((rmse, mape))\n",
        "      \n",
        "  for i, (rmse, mape) in enumerate(errors):\n",
        "      print(f\"Prognozė {i + 1}: VKNŠ = {rmse:.2f}, VAPP = {mape:.2f}%\")\n",
        "\n",
        "  return errors\n"
      ],
      "metadata": {
        "id": "-IWjpxEDZczu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naivus prognozuotojas"
      ],
      "metadata": {
        "id": "7vvSWu4_Z85k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naivus_prognozuotojas(indexas_nuo, indexas_iki, valandos, diagramos_title):\n",
        "\n",
        "  naive_data = old_duomenys[indexas_nuo-valandos:indexas_iki]\n",
        "  naive_plot = old_duomenys[indexas_nuo:indexas_iki]\n",
        "\n",
        "  naive_data = naive_data[kainos_zona].dropna()\n",
        "  naive_plot = naive_plot[kainos_zona].dropna()\n",
        "\n",
        "  naive_data = naive_data.shift(valandos).dropna()\n",
        "\n",
        "  plt.figure(figsize=(15, 7))\n",
        "  plt.plot(range(len(naive_plot)), naive_plot, label='Reali kaina', color='b')\n",
        "  plt.plot(range(len(naive_data)), naive_data, label='Naivi prognozė', color='r')\n",
        "  plt.xlabel('Valandos')\n",
        "  plt.ylabel('Elektros kaina')\n",
        "  plt.legend()\n",
        "  plt.title(diagramos_title)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "VWG6j6g0arVD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kelių įvesties kintamųjų metodai"
      ],
      "metadata": {
        "id": "4PHdZ64QdYtX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SDV Failų apdirbimas\n",
        "\n"
      ],
      "metadata": {
        "id": "VJ6LuAySdfmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def paruosti_sdv_operating_data(sdv_failas):\n",
        "\n",
        "  sdv_data = read_csv(sdv_failas, sep=';', header = None, skiprows=14, names=[\"Data type\", \"Code\", \"Year\", \"Week\", \"Day\", \"Date\", \"Currency\", \"Hour1\",\"Hour2\",\"Hour3\",\"Hour3B\",\"Hour4\",\"Hour5\",\"Hour6\",\"Hour7\",\"Hour8\",\"Hour9\",\"Hour10\",\"Hour11\",\"Hour12\",\"Hour13\",\"Hour14\",\"Hour15\",\"Hour16\",\"Hour17\",\"Hour18\",\"Hour19\",\"Hour20\",\"Hour21\",\"Hour22\",\"Hour23\",\"Hour24\", \"Sum\"])\n",
        "  sdv_data = sdv_data.drop(columns=['Data type', \"Year\", \"Week\", \"Day\", \"Currency\", \"Hour3B\", \"Sum\"], axis = 1)\n",
        "  sdv_data = sdv_data.loc[sdv_data['Code'].isin(['F', 'P'])]\n",
        "  sdv_melted = sdv_data.melt(id_vars=['Code', 'Date'], var_name = 'Hour', value_name='Value')\n",
        "  sdv_melted['Hour'] = sdv_melted['Hour'].str.replace('Hour', '').astype(int) - 1\n",
        "  sdv_pivoted = sdv_melted.pivot_table(values='Value', index=['Date', 'Hour'], columns='Code').reset_index()\n",
        "  sdv_pivoted['Date'] = pd.to_datetime(sdv_pivoted['Date'], format='%d.%m.%Y') + pd.to_timedelta(sdv_pivoted['Hour'], unit='h')\n",
        "  sdv_pivoted.set_index('Date', inplace=True)\n",
        "  sdv_pivoted = sdv_pivoted.drop(columns=['Hour'], axis=1)\n",
        "  sdv_pivoted = sdv_pivoted.rename(columns={'F': 'Elektros sunaudojimas', 'P': 'Elektros pagaminimas'})\n",
        "  sdv_pivoted = sdv_pivoted.sort_index()\n",
        "\n",
        "  return sdv_pivoted\n",
        "\n",
        "def paruosti_sdv_maksimalius_perdavimus(sdv_capacity):\n",
        "\n",
        "  sdv_cap = read_csv(sdv_capacity, sep = ';', header = None, skiprows=34, encoding=\"ISO-8859-1\", names=['Data type', 'Flow', \"Year\", \"Week\", \"Day\", \"Date\", \"Zones\", \"Hour1\",\"Hour2\",\"Hour3\",\"Hour3B\",\"Hour4\",\"Hour5\",\"Hour6\",\"Hour7\",\"Hour8\",\"Hour9\",\"Hour10\",\"Hour11\",\"Hour12\",\"Hour13\",\"Hour14\",\"Hour15\",\"Hour16\",\"Hour17\",\"Hour18\",\"Hour19\",\"Hour20\",\"Hour21\",\"Hour22\",\"Hour23\",\"Hour24\", \"Sum\"])\n",
        "  sdv_cap = sdv_cap.drop(columns=['Data type', 'Flow', \"Year\", \"Week\", \"Day\", \"Hour3B\", \"Sum\" ])\n",
        "  sdv_cap = sdv_cap.dropna()\n",
        "  sdv_cap = sdv_cap[sdv_cap['Zones'].str.endswith('_LT')]\n",
        "  sdv_cap_melted = sdv_cap.melt(id_vars=['Date', 'Zones'], var_name = 'Hour', value_name='Value')\n",
        "  sdv_cap_melted['Hour'] = sdv_cap_melted['Hour'].str.replace('Hour', '').astype(int) - 1\n",
        "  sdv_cap_pivoted = sdv_cap_melted.pivot_table(values='Value', index=['Date', 'Hour'], columns='Zones').reset_index()\n",
        "  sdv_cap_pivoted['Date'] = pd.to_datetime(sdv_cap_pivoted['Date'], format='%d.%m.%Y') + pd.to_timedelta(sdv_cap_pivoted['Hour'], unit='h')\n",
        "  sdv_cap_pivoted.set_index(['Date'],inplace=True)\n",
        "  sdv_cap_pivoted = sdv_cap_pivoted.drop(columns=['Hour'], axis=1)\n",
        "  sdv_cap_pivoted = sdv_cap_pivoted.add_suffix('_maksimalus_perdavimo_pajegumas')\n",
        "  sdv_cap_pivoted = sdv_cap_pivoted.sort_index()\n",
        "\n",
        "  return sdv_cap_pivoted\n",
        "\n",
        "def paruosti_sdv_dabartinius_perdavimus(sdv_flow):\n",
        "\n",
        "  flow = read_csv(sdv_flow, sep=';', header = None, skiprows=35, encoding=\"ISO-8859-1\", decimal=',', names=['Data type', 'Flow', \"Year\", \"Week\", \"Day\", \"Date\", \"Zones\", \"Hour1\",\"Hour2\",\"Hour3\",\"Hour3B\",\"Hour4\",\"Hour5\",\"Hour6\",\"Hour7\",\"Hour8\",\"Hour9\",\"Hour10\",\"Hour11\",\"Hour12\",\"Hour13\",\"Hour14\",\"Hour15\",\"Hour16\",\"Hour17\",\"Hour18\",\"Hour19\",\"Hour20\",\"Hour21\",\"Hour22\",\"Hour23\",\"Hour24\", \"Sum\"])\n",
        "  flow = flow.fillna(0.0)\n",
        "  flow = flow.head(-1)\n",
        "  flow = flow.drop(columns=['Data type', 'Flow', \"Year\", \"Week\", \"Day\", \"Hour3B\", \"Sum\" ])\n",
        "  flow = flow[flow['Zones'].str.endswith('_LT', na=False)]\n",
        "  flow_melted = flow.melt(id_vars=['Date', 'Zones'], var_name = 'Hour', value_name='Value')\n",
        "  flow_melted['Hour'] = flow_melted['Hour'].str.replace('Hour', '').astype(int) - 1\n",
        "  flow_pivoted = flow_melted.pivot_table(values='Value', index=['Date', 'Hour'], columns='Zones').reset_index()\n",
        "  flow_pivoted['Date'] = pd.to_datetime(flow_pivoted['Date'], format='%d.%m.%Y') + pd.to_timedelta(flow_pivoted['Hour'], unit='h')\n",
        "  flow_pivoted.set_index(['Date'],inplace=True)\n",
        "  flow_pivoted = flow_pivoted.drop(columns=['Hour'], axis=1)\n",
        "  flow_pivoted = flow_pivoted.add_suffix('_dabartinis_perdavimo_pajegumas')\n",
        "  flow_pivoted = flow_pivoted.sort_index()\n",
        "\n",
        "  return flow_pivoted\n",
        "\n",
        "\n",
        "def paruosti_sdv_is_aplanko(aplankas, duomenu_tipas):\n",
        "  visi_failai = sorted(glob.glob(os.path.join(aplankas, \"*.sdv\")))\n",
        "  li = []\n",
        "  if duomenu_tipas == 'operaciniai':\n",
        "    metodas = paruosti_sdv_operating_data\n",
        "  if duomenu_tipas == 'maksimalus_perdavimai':\n",
        "    metodas = paruosti_sdv_maksimalius_perdavimus\n",
        "  if duomenu_tipas == 'dabartiniai_perdavimai':\n",
        "    metodas = paruosti_sdv_dabartinius_perdavimus\n",
        "\n",
        "  for failo_pav in visi_failai:\n",
        "    print(failo_pav)\n",
        "    sdv = metodas(failo_pav)\n",
        "    li.append(sdv)\n",
        "\n",
        "  return li\n",
        "\n"
      ],
      "metadata": {
        "id": "fYAeCB2Jdj4e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sujungimas į vieną bendrą failą (pavyzdys su 2023 metais):"
      ],
      "metadata": {
        "id": "YuAq1lvGdvta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "operaciniai_li = paruosti_sdv_is_aplanko('/content/drive/MyDrive/Bakalauras/Nordpool_sdv_duomenys/Lithuania/2023', 'operaciniai')\n",
        "maksimalus_perdavimai_li = paruosti_sdv_is_aplanko('/content/drive/MyDrive/Bakalauras/Nordpool_sdv_duomenys/Capacity/2023', 'maksimalus_perdavimai')\n",
        "dabartiniai_perdavimai_li = paruosti_sdv_is_aplanko('/content/drive/MyDrive/Bakalauras/Nordpool_sdv_duomenys/Flow/2023', 'dabartiniai_perdavimai')\n",
        "\n",
        "operaciniai_df = pd.concat(operaciniai_li, axis=0)\n",
        "maksimalus_df = pd.concat(maksimalus_perdavimai_li, axis=0)\n",
        "maksimalus_df = maksimalus_df.fillna(0.0)\n",
        "\n",
        "dabartiniai_df = pd.concat(dabartiniai_perdavimai_li, axis=0)\n",
        "dabartiniai_df = dabartiniai_df.fillna(0.0)\n",
        "\n",
        "bendras_df = pd.concat([operaciniai_df, maksimalus_df, dabartiniai_df], axis=1)\n",
        "\n",
        "bendras_df = bendras_df['2020-01-01 00:00:00':]\n",
        "\n",
        "nuo = bendras_df.head(1).index[0].strftime('%Y-%m-%d %H:%M:%S')\n",
        "iki = bendras_df.tail(1).index[0].strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "kainos_zona = 'LT'\n",
        "kainos = gauti_duomenu_rinkini('/content/drive/MyDrive/Bakalauras/Nordpool_duomenys', 'LT')\n",
        "\n",
        "kainos['Valandos'] = kainos['Valandos'].apply(lambda x: int(x.split('-')[0]))\n",
        "\n",
        "kainos['Data'] = pd.to_datetime(kainos['Data'] + ' ' + kainos['Valandos'].astype(str) + ':00', format=\"%d-%m-%Y %H:%M\")\n",
        "\n",
        "kainos = kainos.drop(columns=['Valandos'])\n",
        "\n",
        "kainos = kainos.set_index('Data')\n",
        "\n",
        "kainos_df = kainos.sort_index()\n",
        "\n",
        "kainos_df = kainos_df.rename(columns={'LT':'Kaina'})\n",
        "\n",
        "kainos_df = kainos_df[nuo:iki]\n",
        "\n",
        "pilnai_bendras_su_kainomis_df = pd.concat([kainos_df, bendras_df], axis=1)"
      ],
      "metadata": {
        "id": "wEdkuJfzdygA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kelių įvesties kintamųjų ITAMNT metodai"
      ],
      "metadata": {
        "id": "9zuSR9a3efLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "F54strOcemnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sukurti_duomenu_rinkini(duomenys, n_ivestis=72, n_isvestis=24):\n",
        "\n",
        "  X, Y = [], []\n",
        "  for i in range(len(duomenys) - n_ivestis - n_isvestis + 1):\n",
        "    X.append(duomenys[i:(i + n_ivestis), 1:])\n",
        "    Y.append(duomenys[i + n_ivestis:i + n_ivestis + n_isvestis, 0])\n",
        "\n",
        "  return np.array(X), np.array(Y)\n",
        "\n",
        "def duomenys_multivariate_prognozei(duomenys, n_ivestis=72, n_isvestis=24, train_procentai=0.8):\n",
        "\n",
        "  data  = duomenys.values\n",
        "  scaleris_x = MinMaxScaler(feature_range=(0, 1))\n",
        "  scaleris_y = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "  scaled_data_x = scaleris_x.fit_transform(data[:, 1:])\n",
        "  scaled_data_y = scaleris_y.fit_transform(data[:, 0].reshape(-1, 1))\n",
        "  scaled_data = np.hstack((scaled_data_y, scaled_data_x))\n",
        "\n",
        "  X, Y = sukurti_duomenu_rinkini(scaled_data, n_ivestis, n_isvestis)\n",
        "\n",
        "  train_dydis = int(len(X) * train_procentai)\n",
        "  X_train, Y_train = X[:train_dydis], Y[:train_dydis]\n",
        "  X_test, Y_test = X[train_dydis:], Y[train_dydis:]\n",
        "\n",
        "  # Perdaryti duomenys į LSTM sluoksniams reikiamus (samples, timesteps, features)\n",
        "  X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
        "  X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
        "\n",
        "  return X_train, Y_train, X_test, Y_test, scaleris_y\n",
        "\n",
        "def mokyti_multivariate_itamnt(X_train, Y_train, epizodu_sk, neuronu_sk, n_isvestis):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(neuronu_sk, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "  model.add(Dense(n_isvestis))\n",
        "  optimizer = Adam(learning_rate=0.001)\n",
        "  model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "\n",
        "  model.fit(X_train, Y_train, epochs=epizodu_sk, batch_size=1, verbose=1, shuffle=False)\n",
        "\n",
        "  return model\n",
        "\n",
        "def multivariate_prognoze(modelis, X_duomenys, Y_duomenys, scaleris_y):\n",
        "\n",
        "  prog = modelis.predict(X_duomenys)\n",
        "  prog = scaleris_y.inverse_transform(prog)\n",
        "\n",
        "  orig_duom = scaleris_y.inverse_transform(Y_duomenys)\n",
        "\n",
        "  return orig_duom, prog\n",
        "\n",
        "def prognoziu_tikslumas(orig, prog):\n",
        "\n",
        "  rmse = np.sqrt(mean_squared_error(orig, prog))\n",
        "  print('VKNŠ:', rmse)\n",
        "\n",
        "def palyginamasis_df(orig, prog):\n",
        "\n",
        "  palyginimo_df = pd.DataFrame({'Reali': orig.flatten(), 'Prognozė': prog.flatten()})\n",
        "  print(f'Pirmosios 24h:\\n{palyginimo_df.head(24)}')\n",
        "\n",
        "  return palyginimo_df\n",
        "\n",
        "def multivariate_diagrama(orig, prog, pavadinimas):\n",
        "\n",
        "  plt.figure(figsize=(15, 8))\n",
        "  plt.plot(orig[:, 0], label='Reali kaina')\n",
        "  plt.plot(prog[:, 0], label='Prognozė')\n",
        "  plt.xlabel('Valandos')\n",
        "  plt.ylabel('Kaina EUR/MWh')\n",
        "  plt.title(pavadinimas)\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "hVQvrxxhekHd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}